{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529e9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # We can suppress the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57512784",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa22c1339d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c78d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import re\n",
    "# import tensorflow as tf\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28c65e",
   "metadata": {},
   "source": [
    "I will use the functionality of Image Datasource of spark to collect and process images in bytes, and then start processing the images for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443e6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folders = ['/CA1/Images/BakedPotato/','/CA1/Images/Pizza/','/CA1/Images/Taco/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e4e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_rdd = spark.sparkContext.binaryFiles(','.join(images_folders))\n",
    "# images_rdd = spark.sparkContext.binaryFiles('hdfs://172.24.144.178:9000/CA1/Images/Ireland/Ireland_001.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d83df95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.api.java.JavaPairRDD@47722162"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b73c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data):\n",
    "    file_path, image_data = data\n",
    "#     image = Image.open(BytesIO(image_data))\n",
    "#     image_array = np.array(image)\n",
    "    \n",
    "    file_name = file_path.split('/')[-1]\n",
    "    file_name_without_ext = file_name.split(\".\")[0]\n",
    "    label,name = file_name_without_ext.split('_')[0], file_name_without_ext.split('_')[1]\n",
    "    \n",
    "    return name, label, image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec485489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "imageDf = images_rdd.map(lambda x: extract_data(x)).toDF([\"Name\",\"Label\",\"Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f29712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pandasImagesDF = imageDf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6c8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE=225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c621265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(data, target_size=(IMG_SHAPE,IMG_SHAPE)):\n",
    "    imgbytes = BytesIO(data)\n",
    "    image = Image.open(imgbytes)\n",
    "    resized_img = image.resize(target_size, Image.ANTIALIAS)\n",
    "    with BytesIO() as output:\n",
    "        resized_img.save(output, format=\"PNG\")\n",
    "        new_image = Image.open(output)\n",
    "\n",
    "        array = np.asarray(new_image).reshape([target_size[0],target_size[1],3])\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "494c89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasImagesDF[\"Data\"] = pandasImagesDF[\"Data\"].apply(lambda x: processImage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af147bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasImagesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eba5be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasImagesDF = pandasImagesDF.sort_values(by=[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a8bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3275 entries, 0 to 3274\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    3275 non-null   object\n",
      " 1   Label   3275 non-null   object\n",
      " 2   Data    3275 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 102.3+ KB\n"
     ]
    }
   ],
   "source": [
    "pandasImagesDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66401740",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCATEGORIES = len(pandasImagesDF[\"Label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d82b1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NCATEGORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf80bf8",
   "metadata": {},
   "source": [
    "Importing from Keras functionality necessary to implement CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeff7618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 23:53:39.173531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-22 23:53:40.133782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Input\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c44bdc",
   "metadata": {},
   "source": [
    "Now we are to split the data using train_test_split function to use Kfold and improve the perfomance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b85ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pandasImagesDF[\"Data\"],pandasImagesDF[\"Label\"],test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00be1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "y_test = np.array(y_test).reshape(-1,1)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1ffbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9915da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2292, 225, 225, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d7277b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train,(X_train.shape[0],IMG_SHAPE,IMG_SHAPE,3)).astype(np.float32)\n",
    "X_test = np.reshape(X_test,(X_test.shape[0],IMG_SHAPE,IMG_SHAPE,3)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1040f4",
   "metadata": {},
   "source": [
    "Because the pixels are from 0 to 255, We have to normalize the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7788f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train/=255\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad75f3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2292, 225, 225, 3), (983, 225, 225, 3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2e194aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2292, 3), (983, 3))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c36fcb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 23:53:52.395416: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.612908: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.612959: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.617600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.617715: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.617766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.767317: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.767391: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.767400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-22 23:53:52.767441: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-22 23:53:52.767975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(IMG_SHAPE, IMG_SHAPE, 3)))  # 225x225 RGB images\n",
    "model.add(Conv2D(32,kernel_size=(3,3),strides=(1,1),padding=\"valid\", activation=\"relu\"))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation=\"relu\"))\n",
    "model.add(MaxPool2D(3))\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(2))\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(2))\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(NCATEGORIES,activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"category_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea5eb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0fc309",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51399/404332619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548b902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparePredictions(predictionsValues, expectedValues):\n",
    "    correct = 0\n",
    "    for x in range(len(predictionsValues)):\n",
    "        if predictionsValues[x] == expectedValues[x]:\n",
    "            correct+=1\n",
    "    \n",
    "    print(f'Correct predictions {correct}/{len(predictionsValues)}. Percent {correct/len(predictionsValues)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd54b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparePredictions(np.argmax(pred, axis=1),np.argmax(y_test[:25], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61052093",
   "metadata": {},
   "source": [
    "### Trying Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pandasImagesDF[\"Data\"],pandasImagesDF[\"Label\"],test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "y_test = np.array(y_test).reshape(-1,1)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "X_train = np.stack(X_train)\n",
    "X_train = np.reshape(X_train,(X_train.shape[0],IMG_SHAPE,IMG_SHAPE,3)).astype(np.float32)\n",
    "X_train/=255\n",
    "\n",
    "X_test = np.stack(X_test)\n",
    "X_test = np.reshape(X_test,(X_test.shape[0],IMG_SHAPE,IMG_SHAPE,3)).astype(np.float32)\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fec006",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Random rotation between 0 and 20 degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width by up to 10%\n",
    "    height_shift_range=0.1,  # Randomly shift the height by up to 10%\n",
    "    shear_range=0.2,  # Shear intensity (shear angle in counter-clockwise direction in radians)\n",
    "    zoom_range=0.2,  # Randomly zoom in by up to 20%\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Fill mode for points outside the input boundaries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Type of X_train:\", type(X_train))\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Type of y_train:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented_generator = datagen.flow(np.array(X_train), np.array(y_train), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf86821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67b5fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Get a batch of augmented data\n",
    "# images, labels = next(augmented_generator)\n",
    "\n",
    "# # Visualize the augmented images\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(9):\n",
    "#     plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.title(f'Label: {labels[i]}')\n",
    "#     plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece404ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import RandomContrast, RandomBrightness, RandomRotation, RandomFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAugmented = Sequential()\n",
    "dataAugmented.add(RandomContrast(0.7))\n",
    "dataAugmented.add(RandomBrightness(0.7))\n",
    "dataAugmented.add(RandomRotation(0.4))\n",
    "dataAugmented.add(RandomFlip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21499fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAugmented = Sequential()\n",
    "modelAugmented.add(Input(shape=(IMG_SHAPE, IMG_SHAPE, 3)))  # 225x225 RGB images\n",
    "modelAugmented.add(dataAugmented)\n",
    "modelAugmented.add(Conv2D(32,kernel_size=(3,3),strides=(1,1),padding=\"valid\", activation=\"relu\"))\n",
    "modelAugmented.add(Conv2D(32,kernel_size=(3,3),activation=\"relu\"))\n",
    "modelAugmented.add(MaxPool2D(3))\n",
    "modelAugmented.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "modelAugmented.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "modelAugmented.add(MaxPool2D(2))\n",
    "modelAugmented.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "modelAugmented.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "modelAugmented.add(MaxPool2D(2))\n",
    "modelAugmented.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "modelAugmented.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "modelAugmented.add(MaxPool2D(2))\n",
    "\n",
    "modelAugmented.add(Flatten())\n",
    "\n",
    "\n",
    "modelAugmented.add(Dense(128, activation=\"relu\"))\n",
    "modelAugmented.add(Dense(NCATEGORIES,activation=\"sigmoid\"))\n",
    "\n",
    "modelAugmented.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a310ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAugmented.fit(X_train, y_train, batch_size=32, epochs=30, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67de974",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelAugmented.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c669c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = modelAugmented.predict(X_test[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparePredictions(np.argmax(pred, axis=1),np.argmax(y_test[:25], axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
